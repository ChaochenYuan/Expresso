{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "if hasattr(__builtins__,'__IPYTHON__'):\n",
    "    sysName='DY'\n",
    "    sysfiles='/eos/cms/store/group/phys_egamma/akapoor/ChargeMisID/newsamples2/06544C90-EFDF-E811-80E6-842B2B6F5D5C.root'\n",
    "    saveRootFile=True\n",
    "    outfolder='Output'\n",
    "    outsuffix='1'\n",
    "    debugprint=True\n",
    "    analysis='Analyses/TTH'\n",
    "    multithreaded=False\n",
    "    xsec=1.00\n",
    "    istype='mc'\n",
    "    #!python3 -m pip install correctionlib\n",
    "    path = '/eos/user/a/akapoor/.local/bin'\n",
    "    os.environ['PATH'] += ':'+path\n",
    "    #branchlist=\"(ChargeFlip_Category|MyElectron_pt)\"\n",
    "else:\n",
    "    parser = argparse.ArgumentParser(description='Options for the analyzer')\n",
    "    parser.add_argument('--name', metavar='n', action='store', type=str,help='short name of the physics process/Data sample', required=True)\n",
    "    parser.add_argument('--file', metavar='f', action='store', type=str,help='location of files',required=True)\n",
    "    parser.add_argument('--saveroot',action='store_true', help='save root file',default=False)\n",
    "    parser.add_argument('--debugprint',action='store_true', help='print analysis settings for debug',default=False)\n",
    "    parser.add_argument('--outfolder', metavar='of', action='store', type=str,help='location of output',default='Output',required=True)\n",
    "    parser.add_argument('--outsuffix', metavar='os', action='store', type=str,help='suffix to recognize job',default='Output')\n",
    "    parser.add_argument('--analysis', metavar='ana', action='store', type=str,help='Folder name that has analysis configs',default='Output',required=True)\n",
    "    parser.add_argument('--multithreaded', action='store_true', help='mt',default=False)\n",
    "    parser.add_argument('--xsec', metavar='xsec', action='store', type=float, help='xsec',default=1,required=True )\n",
    "    parser.add_argument('--istype', metavar='istype', action='store', type=str, help='data or mc',default='mc',required=True )\n",
    "    #parser.add_argument('--branchlist', metavar='bl', action='store', type=str,help='branches to store in skim',default=\"(MyElectron_eta|MyElectron_pt)\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    sysName=str(args.name)\n",
    "    sysfiles=str(args.file)\n",
    "    saveRootFile=args.saveroot\n",
    "    outfolder=str(args.outfolder)\n",
    "    outsuffix=str(args.outsuffix)\n",
    "    analysis=str(args.analysis)\n",
    "    debugprint=args.debugprint\n",
    "    multithreaded=args.multithreaded\n",
    "    xsec=args.xsec\n",
    "    istype=args.istype\n",
    "    #branchlist=str(args.branchlist)\n",
    "\n",
    "os.system(\"mkdir \"+outfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/00\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "if multithreaded:\n",
    "    ROOT.ROOT.EnableImplicitMT()\n",
    "\n",
    "#ROOT.gROOT.ProcessLine(\".L /correctionlib/correctionlib/include/_core.cpython-38-x86_64-linux-gnu.so\");\n",
    "#ROOT.gSystem.Load('_core.cpython-38-x86_64-linux-gnu.so')\n",
    "ROOT.gInterpreter.AddIncludePath(\"./include/modules/\");\n",
    "#ROOT.gInterpreter.AddIncludePath(\"./correctionlib/correctionlib/include/\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "modules = [os.path.basename(x) for x in glob.glob('./include/modules/*.h')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading modules ['GenerateDecayTime.h', 'Helper.h']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading modules {modules}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mo in modules:\n",
    "    ROOT.gInterpreter.ProcessLine('#include \"'+mo+'\"')\n",
    "#ROOT.gInterpreter.ProcessLine('#include \"correction.h\"')\n",
    "\n",
    "from include.PyHelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "ObjectCutsFile=analysis+\"/ObjectCuts.yaml\"\n",
    "DefinitionsFile=analysis+\"/Definitions.yaml\"\n",
    "SelectionsFile=analysis+\"/Selections.yaml\"\n",
    "BranchesToSaveFile=analysis+\"/BranchesToSave.yaml\"\n",
    "WeightConfig=analysis+\"/WeightConfig.yaml\"\n",
    "ApplyWeights=analysis+\"/ApplyWeights.yaml\"\n",
    "Histostosave=analysis+\"/Histos.yaml\"\n",
    "\n",
    "ObjectCuts = yaml.safe_load(open(ObjectCutsFile, 'r'))\n",
    "Definitions = yaml.safe_load(open(DefinitionsFile, 'r'))\n",
    "Selections = yaml.safe_load(open(SelectionsFile, 'r'))\n",
    "BranchesToSave = yaml.safe_load(open(BranchesToSaveFile, 'r'))\n",
    "WeightConfig = yaml.safe_load(open(WeightConfig, 'r'))\n",
    "ApplyWeights = yaml.safe_load(open(ApplyWeights, 'r'))\n",
    "Histos=yaml.safe_load(open(Histostosave, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listtostdvector(mylist):\n",
    "    mynewList = ROOT.std.vector('std::string')()\n",
    "    for element in mylist:\n",
    "        mynewList.push_back(element)\n",
    "    return mynewList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import correctionlib\n",
    "correctionlib.register_pyroot_binding()\n",
    "\n",
    "Ana= MyAnalyzer()\n",
    "for key in ObjectCuts.keys():\n",
    "    exec(f'{key}mask=ObjectMask()')\n",
    "    for cut in ObjectCuts[key]:\n",
    "        exec(f'{key}mask.addcut(\"{cut}\")')\n",
    "    exec(f'mask={key}mask.mask')\n",
    "    exec(f'Ana.definition(\"{key}\",{key}mask.mask)')\n",
    "for key in Definitions.keys():\n",
    "    Ana.definition(key,Definitions[key])\n",
    "for key in Selections.keys():\n",
    "    Ana.sel(key,Selections[key])\n",
    "for corr in WeightConfig:\n",
    "    ROOT.gInterpreter.Declare(corr)\n",
    "for key in ApplyWeights:\n",
    "    Ana.definition(key,ApplyWeights[key])\n",
    "    \n",
    "    \n",
    "processname=sysName\n",
    "processdict={'Files':sysfiles,'Type':istype,'Tree':'Events','Xsec':xsec}\n",
    "Ana.process(processname,processdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TClass::Init>: no dictionary for class edm::ProcessHistory is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm::ProcessConfiguration is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm::ParameterSetBlob is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm::Hash<1> is available\n",
      "Warning in <TClass::Init>: no dictionary for class pair<edm::Hash<1>,edm::ParameterSetBlob> is available\n"
     ]
    }
   ],
   "source": [
    "Total=Ana.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=Ana.PD[sysName]['RDF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Dumping the analysis graph\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Object Mask Cuts from Analyses/TTH/ObjectCuts.yaml\n",
      "{\n",
      "   \"GoodElectrons\": [\n",
      "      \"Electron_pt > 10\",\n",
      "      \"Electron_sieie<(0.011+0.019*(abs(Electron_eta+Electron_deltaEtaSC)>1.479))\",\n",
      "      \"abs(Electron_dxy)< 0.05\",\n",
      "      \"abs(Electron_dz)< 0.1\",\n",
      "      \"Electron_mvaTTH > 0.8\",\n",
      "      \"Electron_hoe<0.1\",\n",
      "      \"Electron_eInvMinusPInv>-0.04\",\n",
      "      \"Electron_sip3d<8\",\n",
      "      \"Electron_convVeto\",\n",
      "      \"Electron_miniPFRelIso_all<0.40\",\n",
      "      \"Electron_lostHits==0\"\n",
      "   ]\n",
      "}\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "All the definitions from Analyses/TTH/Definitions.yaml\n",
      "{\n",
      "   \"Nel\": \"Sum(GoodElectrons)\",\n",
      "   \"elpt\": \"Take(Electron_pt[GoodElectrons], Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"eleta\": \"Take(Electron_eta[GoodElectrons], Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"elphi\": \"Take(Electron_phi[GoodElectrons], Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"elmass\": \"Take(Electron_mass[GoodElectrons], Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"elcharge\": \"Take(Electron_charge[GoodElectrons], Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"elgenPartIdx\": \"Take(Electron_genPartIdx[GoodElectrons], Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"eltightCharge\": \"Take(Electron_tightCharge[GoodElectrons],Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"eljetIdx\": \"Take(Electron_jetIdx[GoodElectrons], Reverse(Argsort(Electron_pt[GoodElectrons])))\",\n",
      "   \"eldeepjet\": \"Varbutindices(Jet_btagDeepFlavB,eljetIdx)\",\n",
      "   \"Dielectron_mass\": \"ComputeInvariantMass(elpt, eleta, elphi, elmass)\",\n",
      "   \"ChargeFlip_Category\": \"((elpt.size()>1) ? ChargeFlip_Category(elpt[0],elpt[1],eleta[0],eleta[1]):-999)\"\n",
      "}\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "All the Event Selections from Analyses/TTH/Selections.yaml\n",
      "{\n",
      "   \"Sum(GoodElectrons) == 2\": \"Two or more good electrons\",\n",
      "   \"(eldeepjet[0]<0.3033 && eldeepjet[1]<0.3033 && eldeepjet[0]>-999 && eldeepjet[1]>-999)\": \"DeepJet cuts on ele\",\n",
      "   \"(Dielectron_mass<121) && (Dielectron_mass>61)\": \"Z mass cut\",\n",
      "   \"((Sum(GoodElectrons) >1) ? DeltaR(eleta[0],elphi[0],eleta[1],elphi[1]):0)>0.4\": \"DeltaR cut\",\n",
      "   \"Flag_goodVertices && Flag_globalSuperTightHalo2016Filter && Flag_HBHENoiseFilter\": \"Quality1\",\n",
      "   \"Flag_HBHENoiseIsoFilter && Flag_EcalDeadCellTriggerPrimitiveFilter && Flag_BadPFMuonFilter\": \"Quality3\"\n",
      "}\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Sample information provided as options\n",
      "{\n",
      "   \"Files\": \"/eos/cms/store/group/phys_egamma/akapoor/ChargeMisID/newsamples2/06544C90-EFDF-E811-80E6-842B2B6F5D5C.root\",\n",
      "   \"Type\": \"mc\",\n",
      "   \"Tree\": \"Events\",\n",
      "   \"Xsec\": 1.0\n",
      "}\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Branches to save taken from Analyses/TTH/BranchesToSave.yaml\n",
      "[\n",
      "   \"elpt\"\n",
      "]\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Weight Config\n",
      "[\n",
      "   \"auto csetEl_2016postID = correction::CorrectionSet::from_file(\\\"/cvmfs/cms.cern.ch/rsync/cms-nanoAOD/jsonpog-integration/POG/EGM/2016postVFP_UL/electron.json.gz\\\")->at(\\\"UL-Electron-ID-SF\\\");\"\n",
      "]\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Weights avilable\n",
      "{\n",
      "   \"leadElSF\": \"csetEl_2016postID->evaluate({\\\"2016postVFP\\\", \\\"sf\\\", \\\"wp90iso\\\", std::abs(eleta[0]), elpt[0]})\"\n",
      "}\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "Histograms that will be saved\n",
      "[\n",
      "   \"leadElSF\",\n",
      "   \"elpt\"\n",
      "]\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "if debugprint:\n",
    "    \n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print('Dumping the analysis graph')\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Object Mask Cuts from {ObjectCutsFile}')\n",
    "    print(json.dumps(ObjectCuts, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'All the definitions from {DefinitionsFile}')\n",
    "    print(json.dumps(Definitions, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'All the Event Selections from {SelectionsFile}')\n",
    "    print(json.dumps(Selections, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Sample information provided as options')\n",
    "    print(json.dumps(processdict, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Branches to save taken from {BranchesToSaveFile}')\n",
    "    print(json.dumps(BranchesToSave, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Weight Config')\n",
    "    print(json.dumps(WeightConfig, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Weights avilable')\n",
    "    print(json.dumps(ApplyWeights, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    print(f'Histograms that will be saved')\n",
    "    print(json.dumps(Histos, indent=3))\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')\n",
    "    if not hasattr(__builtins__,'__IPYTHON__'):\n",
    "        print('Skimmer options used')\n",
    "        print(args)\n",
    "    print('---------------------------------------------------')\n",
    "    print('---------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF.Display({\"event\",\"elpt\",\"eldeepjet\"}).Print()\n",
    "cutflow=DF.Report()\n",
    "Final=DF.Count()\n",
    "hists=[]\n",
    "for hist in Histos:\n",
    "    hists.append(DF.Histo1D(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the Action Graph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Output/ActionGraph.dot.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Saving the Action Graph')\n",
    "ROOT.RDF.SaveGraph(cutflow, f'{outfolder}/ActionGraph.dot')\n",
    "from graphviz import render\n",
    "render('dot', 'png', f'{outfolder}/ActionGraph.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Check issue in Varbutindices, size of variables not compatible\n",
      "Two or more good electrons: pass=120721     all=1593385    -- eff=7.58 % cumulative eff=7.58 %\n",
      "DeepJet cuts on ele: pass=119050     all=120721     -- eff=98.62 % cumulative eff=7.47 %\n",
      "Z mass cut: pass=114679     all=119050     -- eff=96.33 % cumulative eff=7.20 %\n",
      "DeltaR cut: pass=114676     all=114679     -- eff=100.00 % cumulative eff=7.20 %\n",
      "Quality1  : pass=114640     all=114676     -- eff=99.97 % cumulative eff=7.19 %\n",
      "Quality3  : pass=114590     all=114640     -- eff=99.96 % cumulative eff=7.19 %\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if saveRootFile:\n",
    "    #BRS=BranchesToSave.replace(\" \", \"\")\n",
    "    outfilenow=outfolder+\"/output_\"+outsuffix+\".root\"\n",
    "    snapshot=DF.Snapshot(\"Events\",outfilenow,listtostdvector(BranchesToSave))\n",
    "    #fdf=DF.Snapshot(\"Events\",outfilenow,f\"{BRS}\")\n",
    "    #if debugprint:\n",
    "    cutflow.Print()\n",
    "    #sys.stdout = open(outfolder+\"/CutFlow.csv\", \"a\")\n",
    "    #print(f'{sysfiles}' + \"\\n\")\n",
    "    \n",
    "    #sys.stdout.close()\n",
    "    TotalEvents=Total.GetValue()\n",
    "    FinalEvents=Final.GetValue()\n",
    "    with open(outfolder+\"/Info.csv\", \"a\") as text_file:\n",
    "            #print(driver.current_url)\n",
    "            text_file.write(f'{sysfiles}, {istype}, {xsec}, {FinalEvents}, {TotalEvents}, {round((FinalEvents*100)/TotalEvents,2)}%, {outfilenow}' + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if saveRootFile:\n",
    "    f = ROOT.TFile(outfilenow,\"update\")\n",
    "    for histi in hists:\n",
    "        histi.Write()\n",
    "    f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
